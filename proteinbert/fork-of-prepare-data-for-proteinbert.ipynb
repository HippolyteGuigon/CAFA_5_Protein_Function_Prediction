{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyfastx obonet protein-bert","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:38:50.002320Z","iopub.execute_input":"2023-04-22T01:38:50.002733Z","iopub.status.idle":"2023-04-22T01:39:17.914220Z","shell.execute_reply.started":"2023-04-22T01:38:50.002700Z","shell.execute_reply":"2023-04-22T01:39:17.912927Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyfastx\n  Downloading pyfastx-1.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (903 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m903.2/903.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting obonet\n  Downloading obonet-1.0.0-py3-none-any.whl (9.2 kB)\nCollecting protein-bert\n  Downloading protein_bert-1.0.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from obonet) (2.6.3)\nRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (from protein-bert) (0.19.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from protein-bert) (2.11.0)\nCollecting pyfaidx\n  Downloading pyfaidx-0.7.2.1-py3-none-any.whl (28 kB)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from protein-bert) (4.9.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from protein-bert) (1.3.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from protein-bert) (1.21.6)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from protein-bert) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->protein-bert) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->protein-bert) (2022.7.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pyfaidx->protein-bert) (59.8.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyfaidx->protein-bert) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (2.2.0)\nCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (0.2.0)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (2.11.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (1.51.1)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (23.1.21)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (15.0.6.1)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (1.14.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (1.4.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (0.4.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (0.29.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (1.6.3)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (4.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (23.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (3.3.0)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (2.11.0)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->protein-bert) (2.11.0)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons->protein-bert) (2.13.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow->protein-bert) (0.38.4)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (0.6.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (3.4.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (2.28.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (1.35.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (2.2.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->protein-bert) (1.8.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (0.2.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (4.11.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (2022.12.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (3.11.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->protein-bert) (3.2.2)\nInstalling collected packages: pyfastx, pyfaidx, protobuf, obonet, protein-bert\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed obonet-1.0.0 protein-bert-1.0.1 protobuf-3.19.6 pyfaidx-0.7.2.1 pyfastx-1.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pyfastx\nimport obonet\nimport pandas as pd\n\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\nfrom proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:39:17.916578Z","iopub.execute_input":"2023-04-22T01:39:17.918110Z","iopub.status.idle":"2023-04-22T01:39:27.122246Z","shell.execute_reply.started":"2023-04-22T01:39:17.918059Z","shell.execute_reply":"2023-04-22T01:39:27.121233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"![ ! -f train_sequences.fasta ] && cp ../input/cafa-5-protein-function-prediction/Train/train_sequences.fasta .\nfa = pyfastx.Fasta('train_sequences.fasta')\nall_seqs = {s.name: s.seq for s in fa}","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:39:27.123681Z","iopub.execute_input":"2023-04-22T01:39:27.124638Z","iopub.status.idle":"2023-04-22T01:39:31.800680Z","shell.execute_reply.started":"2023-04-22T01:39:27.124601Z","shell.execute_reply":"2023-04-22T01:39:31.799095Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"url = '../input/cafa-5-protein-function-prediction/Train/go-basic.obo'\ngraph = obonet.read_obo(url)\nall_terms = list(graph.nodes())\nall_labels = list(range(len(all_terms)))\nterm_to_label = {term: label for term, label in zip(all_terms, all_labels)}","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:39:31.804452Z","iopub.execute_input":"2023-04-22T01:39:31.804975Z","iopub.status.idle":"2023-04-22T01:39:40.465479Z","shell.execute_reply.started":"2023-04-22T01:39:31.804898Z","shell.execute_reply":"2023-04-22T01:39:40.464306Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/cafa-5-protein-function-prediction/Train/train_terms.tsv', sep='\\t')\n\n# Filter out terms with only 1 sample (since they cannot be splitted into train and validation sets)\ntrain = train.groupby('term').filter(lambda x: x['EntryID'].count() >= 2)\n\ntrain['text'] = train['EntryID'].map(lambda x: all_seqs[x])\ntrain['label'] = train['term'].map(lambda x: term_to_label[x])","metadata":{"execution":{"iopub.status.busy":"2023-04-22T02:12:24.297763Z","iopub.execute_input":"2023-04-22T02:12:24.298222Z","iopub.status.idle":"2023-04-22T02:12:38.930737Z","shell.execute_reply.started":"2023-04-22T02:12:24.298185Z","shell.execute_reply":"2023-04-22T02:12:38.929408Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"![ ! -f epoch_92400_sample_23500000.pkl ] && wget ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/epoch_92400_sample_23500000.pkl\n\nOUTPUT_TYPE = OutputType(False, 'categorical')\nUNIQUE_LABELS = all_labels\nOUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n\ntrain_set, valid_set = train_test_split(train, stratify = train['label'], test_size = 0.1, random_state = 0)\n\npretrained_model_generator, input_encoder = load_pretrained_model(\n    local_model_dump_dir = '.',\n    local_model_dump_file_name = 'epoch_92400_sample_23500000.pkl'\n)\n\nmodel_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n\ntraining_callbacks = [\n    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n]\n\nfinetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['text'], train_set['label'], valid_set['text'], valid_set['label'], \\\n        seq_len = 512, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T02:14:20.957700Z","iopub.execute_input":"2023-04-22T02:14:20.958177Z","iopub.status.idle":"2023-04-22T02:14:44.031860Z","shell.execute_reply.started":"2023-04-22T02:14:20.958134Z","shell.execute_reply":"2023-04-22T02:14:44.029983Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[2023_04_22-02:14:33] Training set: Filtered out 3848 of 4823218 (0.1%) records of lengths exceeding 8190.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/37985958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['text'], train_set['label'], valid_set['text'], valid_set['label'], \\\n\u001b[1;32m     23\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs_per_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin_with_frozen_pretrained_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/finetuning.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(model_generator, input_encoder, output_spec, train_seqs, train_raw_Y, valid_seqs, valid_raw_Y, seq_len, batch_size, max_epochs_per_stage, lr, begin_with_frozen_pretrained_layers, lr_with_frozen_pretrained_layers, n_final_epochs, final_seq_len, final_lr, callbacks)\u001b[0m\n\u001b[1;32m     46\u001b[0m         final_seq_len = 1024, final_lr = None, callbacks = []):\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mencoded_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_valid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_train_and_valid_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_raw_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_raw_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin_with_frozen_pretrained_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/finetuning.py\u001b[0m in \u001b[0;36mencode_train_and_valid_sets\u001b[0;34m(train_seqs, train_raw_Y, valid_seqs, valid_raw_Y, input_encoder, output_spec, seq_len)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     encoded_train_set = encode_dataset(train_seqs, train_raw_Y, input_encoder, output_spec, seq_len = seq_len, needs_filtering = True, \\\n\u001b[0;32m--> 156\u001b[0;31m             dataset_name = 'Training set')\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_seqs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalid_raw_Y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/finetuning.py\u001b[0m in \u001b[0;36mencode_dataset\u001b[0;34m(seqs, raw_Y, input_encoder, output_spec, seq_len, needs_filtering, dataset_name, verbose)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mraw_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weigths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weigths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/model_generation.py\u001b[0m in \u001b[0;36mencode_X\u001b[0;34m(self, seqs, seq_len)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         return [\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mtokenize_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_annotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ]\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/model_generation.py\u001b[0m in \u001b[0;36mtokenize_seqs\u001b[0;34m(seqs, seq_len)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Note that tokenize_seq already adds <START> and <END> tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/model_generation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Note that tokenize_seq already adds <START> and <END> tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/tokenization.py\u001b[0m in \u001b[0;36mtokenize_seq\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mother_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<OTHER>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<START>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maa_to_token_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_token_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<END>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proteinbert/tokenization.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mother_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<OTHER>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<START>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maa_to_token_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_token_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0madditional_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<END>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}